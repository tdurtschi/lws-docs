{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lake Wingra Software - Knowledge Base Return to the Home Page . Use the navigation pane to browse content.","title":"Lake Wingra Software - Knowledge Base"},{"location":"#lake-wingra-software-knowledge-base","text":"Return to the Home Page . Use the navigation pane to browse content.","title":"Lake Wingra Software - Knowledge Base"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/","text":"About What is Lake Wingra Software? Hello, I'm Teagan Durtschi, the creator of Lake Wingra Software. Lake Wingra Software was created to connect with great people to work on awesome software. I believe that investing in high-quality code results in better business outcomes. My approach integrates Test-Driven Development , refactoring , and DevOps automation to ensure sustainable, bug-free feature delivery. Since 2022, I've collaborated with teams in various industries including healthcare, manufacturing, retail, and agriculture. I like to hit the ground running and help teams identify high-impact ways to improve their products. Let's Connect! Do you need help building something new or improving your existing software? Let's connect! Send me an email lakewingrasoftware@gmail.com or DM me on LinkedIn . Resumes Looking for a Software Engineering resume ? Looking for a DevOps resume ? About Lake Wingra Lake Wingra is located in Madison, Wisconsin.","title":"About"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/#about","text":"","title":"About"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/#what-is-lake-wingra-software","text":"Hello, I'm Teagan Durtschi, the creator of Lake Wingra Software. Lake Wingra Software was created to connect with great people to work on awesome software. I believe that investing in high-quality code results in better business outcomes. My approach integrates Test-Driven Development , refactoring , and DevOps automation to ensure sustainable, bug-free feature delivery. Since 2022, I've collaborated with teams in various industries including healthcare, manufacturing, retail, and agriculture. I like to hit the ground running and help teams identify high-impact ways to improve their products.","title":"What is Lake Wingra Software?"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/#lets-connect","text":"Do you need help building something new or improving your existing software? Let's connect! Send me an email lakewingrasoftware@gmail.com or DM me on LinkedIn .","title":"Let's Connect!"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/#resumes","text":"Looking for a Software Engineering resume ? Looking for a DevOps resume ?","title":"Resumes"},{"location":"1.%20Lake%20Wingra%20Software/01%20-%20whoAreWe/#about-lake-wingra","text":"Lake Wingra is located in Madison, Wisconsin.","title":"About Lake Wingra"},{"location":"1.%20Lake%20Wingra%20Software/02%20-%20projects/","text":"Open Source Projects Public Bookmarks ( GitHub ) Block Game ( GitHub ) Elevator Saga 2 ( GitHub ) OneLibrary ( Codeberg )","title":"Open Source Projects"},{"location":"1.%20Lake%20Wingra%20Software/02%20-%20projects/#open-source-projects","text":"Public Bookmarks ( GitHub ) Block Game ( GitHub ) Elevator Saga 2 ( GitHub ) OneLibrary ( Codeberg )","title":"Open Source Projects"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/","text":"Test-Driven Development Code quality is one of the biggest factors contributing to effective software delivery. High quality code is important because it allows engineers to ship new features quicker and more confidently. I have found no technique with a higher impact on software quality than Test-Driven Development , or TDD . I'm a huge fan of TDD so just know you will see a very biased argument in favor of TDD here. Arguments against TDD can easily be found with a quick Google search! But to me the benefits of TDD are clear. TDD is simply a really good way to maintain high quality . What is it? TDD is a 3-step software development practice. A simple way to remember the 3 steps is \" Red-Green-Refactor \". First, a developer creates a new automated test that describes some expected behavior of the code. Behaviors are just the various ways your software behaves given different inputs. Here's an example of an expected behavior: \"When the user types an invalid character in the field, it should indicate an error by applying a red outline\" . At this point, the developer runs the test. However, the expected behavior doesn't exist, so the test will fail. In TDD a failing tests is often called a \"red\" test. After seeing the test fail as expected, the developer writes some code to implement the function, for example adding an error state to a text field. Then the developer runs the test again to verify it passes. A passing test is often called \"green\". Finally, when every automated test passes, there is an opportunity to refactor the code. Some common ways to refactor the code include replacing duplicated code with a function call, or renaming a variable to be more descriptive. After the developer has (optionally) refactored the code, it is time to work on the next incremental feature by writing a new test. As you can see, each of the 3 steps follows one of the others, forming a cycle . When developing an application, applying TDD means to repeat the cycle over and over and over again. Red-Green-Refactor . Why Test? The purpose of TDD is to ensure that test coverage remains as high as possible. But test coverage isn't just a metric for its own sake. Let\u2019s step back and ask: why is test coverage important? What really matters at the end of the day is good software. In other words, the app should work! To make sure it works, we test it out. A long time ago, the lifecycle of a software project generally resembled this diagram. A team would build a piece of software, test it out, then ship it. Unfortunately, modern software delivery is not so simple! The reality for nearly all software is that it's never done; it is always being tweaked and improved. Development is an iterative process. Top software companies like Amazon and Google push new updates to their flagship products daily or even multiple times a day. There is a term for this: Continuous Delivery . When developing iteratively, tension is created. We want frequent changes to the code, and we want to deliver quickly, but we also want the app to work. Some teams accept the risk of breaking things, and simply don't test. Other teams pay some slow, error-prone humans to test each version of the app before it gets shipped. The third option is comprehensive automated tests . If the goal is delivering quickly and confidently , the best way to achieve this is with automated test coverage. Invest in Tests One argument against TDD is that writing automated tests takes too long, or it is too hard. I won't argue that it takes time and can be difficult, especially at first. But the other side of the equation deserves exploring. When we invest in tests, what do we get for our efforts? First, as I mentioned earlier, your automated tests replace testing by hand. In many cases manual testing can be eliminated by comprehensive tests. That's probably reason enough to write automated tests. Another major return on investment comes in the form of developer confidence . This is somewhat hard to convey if you haven't experienced it, but it's undeniable for many who have first-hand experience on well-tested codebases. In short, having tests gives you freedom to refactor the code. A great deep dive on this subject is Matthew Parker's Why TDD . Test First One of the biggest arguments against TDD is that the whole idea of writing the test first is unnecessary. But to me, when I think about what makes a test good, the idea of writing them first naturally follows. The main thing a good test should do is pass when things work as expected, and fail when they don't work as expected. It sounds obvious but it's worth saying. As the author of a good test, a developer needs to verify both of these scenarios. In other words, they must try the test on 2 different versions of the code and see that the test passes under the expected condition, and fails under incorrect conditions. I want to emphasize this point: if a test has never failed, it's not a good test . I have encountered many tests that look correct at first glance but never fail due to some bug in the test. So a test should fail. The only remaining question is, at what point in development should the test fail? The test fails first . Congratulations, you're doing TDD! The implementation comes first, then a test which passes. Then at the end , the implementation is temporarily removed to verify the test will fail. This is still effective, but it does add an extra step. For me, the choice is clear. Only writing the test first gives me the confidence I need while avoiding extra work. That's why I TDD! Learn More About TDD Let's chat about TDD or discuss how adopting TDD could improve outcomes for your team! Resources Test-Driven Development - Martin Fowler Test-Driven Development By Example - Kent Beck (Amazon)","title":"Test-Driven Development"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#test-driven-development","text":"Code quality is one of the biggest factors contributing to effective software delivery. High quality code is important because it allows engineers to ship new features quicker and more confidently. I have found no technique with a higher impact on software quality than Test-Driven Development , or TDD . I'm a huge fan of TDD so just know you will see a very biased argument in favor of TDD here. Arguments against TDD can easily be found with a quick Google search! But to me the benefits of TDD are clear. TDD is simply a really good way to maintain high quality .","title":"Test-Driven Development"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#what-is-it","text":"TDD is a 3-step software development practice. A simple way to remember the 3 steps is \" Red-Green-Refactor \". First, a developer creates a new automated test that describes some expected behavior of the code. Behaviors are just the various ways your software behaves given different inputs. Here's an example of an expected behavior: \"When the user types an invalid character in the field, it should indicate an error by applying a red outline\" . At this point, the developer runs the test. However, the expected behavior doesn't exist, so the test will fail. In TDD a failing tests is often called a \"red\" test. After seeing the test fail as expected, the developer writes some code to implement the function, for example adding an error state to a text field. Then the developer runs the test again to verify it passes. A passing test is often called \"green\". Finally, when every automated test passes, there is an opportunity to refactor the code. Some common ways to refactor the code include replacing duplicated code with a function call, or renaming a variable to be more descriptive. After the developer has (optionally) refactored the code, it is time to work on the next incremental feature by writing a new test. As you can see, each of the 3 steps follows one of the others, forming a cycle . When developing an application, applying TDD means to repeat the cycle over and over and over again. Red-Green-Refactor .","title":"What is it?"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#why-test","text":"The purpose of TDD is to ensure that test coverage remains as high as possible. But test coverage isn't just a metric for its own sake. Let\u2019s step back and ask: why is test coverage important? What really matters at the end of the day is good software. In other words, the app should work! To make sure it works, we test it out. A long time ago, the lifecycle of a software project generally resembled this diagram. A team would build a piece of software, test it out, then ship it. Unfortunately, modern software delivery is not so simple! The reality for nearly all software is that it's never done; it is always being tweaked and improved. Development is an iterative process. Top software companies like Amazon and Google push new updates to their flagship products daily or even multiple times a day. There is a term for this: Continuous Delivery . When developing iteratively, tension is created. We want frequent changes to the code, and we want to deliver quickly, but we also want the app to work. Some teams accept the risk of breaking things, and simply don't test. Other teams pay some slow, error-prone humans to test each version of the app before it gets shipped. The third option is comprehensive automated tests . If the goal is delivering quickly and confidently , the best way to achieve this is with automated test coverage.","title":"Why Test?"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#invest-in-tests","text":"One argument against TDD is that writing automated tests takes too long, or it is too hard. I won't argue that it takes time and can be difficult, especially at first. But the other side of the equation deserves exploring. When we invest in tests, what do we get for our efforts? First, as I mentioned earlier, your automated tests replace testing by hand. In many cases manual testing can be eliminated by comprehensive tests. That's probably reason enough to write automated tests. Another major return on investment comes in the form of developer confidence . This is somewhat hard to convey if you haven't experienced it, but it's undeniable for many who have first-hand experience on well-tested codebases. In short, having tests gives you freedom to refactor the code. A great deep dive on this subject is Matthew Parker's Why TDD .","title":"Invest in Tests"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#test-first","text":"One of the biggest arguments against TDD is that the whole idea of writing the test first is unnecessary. But to me, when I think about what makes a test good, the idea of writing them first naturally follows. The main thing a good test should do is pass when things work as expected, and fail when they don't work as expected. It sounds obvious but it's worth saying. As the author of a good test, a developer needs to verify both of these scenarios. In other words, they must try the test on 2 different versions of the code and see that the test passes under the expected condition, and fails under incorrect conditions. I want to emphasize this point: if a test has never failed, it's not a good test . I have encountered many tests that look correct at first glance but never fail due to some bug in the test. So a test should fail. The only remaining question is, at what point in development should the test fail? The test fails first . Congratulations, you're doing TDD! The implementation comes first, then a test which passes. Then at the end , the implementation is temporarily removed to verify the test will fail. This is still effective, but it does add an extra step. For me, the choice is clear. Only writing the test first gives me the confidence I need while avoiding extra work. That's why I TDD!","title":"Test First"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#learn-more-about-tdd","text":"Let's chat about TDD or discuss how adopting TDD could improve outcomes for your team!","title":"Learn More About TDD"},{"location":"2.%20Software%20Engineering%20Practices/01-%20tdd/#resources","text":"Test-Driven Development - Martin Fowler Test-Driven Development By Example - Kent Beck (Amazon)","title":"Resources"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/","text":"Refactoring Wikipedia defines refactoring as \"restructuring existing source code\u2014changing the factoring\u2014without changing its external behavior.\" I like this definition, but it is a bit technical. A simple way to think of refactoring is cleaning or re-organizing code. To explain why regular refactoring is important, consider this example drawn from personal experience... A Cautionary Tale A new project begins with a clean slate and developers start hammering away on new features. The codebase is small, so it is easy to see the various pieces and how they fit together. Updating the code is a breeze because there isn't much that can go wrong, and if something breaks it will be easy to notice. Stakeholders are happy with the team's velocity. The team is generally small at this stage and everyone has an intuitive sense of what's going on. Time goes by, and the complexity gradually and steadily increases. After a while, there are dozens of components interacting with each other, and hundreds of individual features supporting several critical user workflows. Each individual contributor only has a partial understanding of the whole system. At this point, the stakeholders are still expecting fast delivery of features. The delivery pressure means things are shipped as soon as they work. Components are added haphazardly without taking time to consider the design of the whole system, code snippets are copy/pasted, and features are shipped without tests. At this point in development, the cost of breaking things is much higher because real users may experience outages. At the same time, it's harder for any single person to grasp how everything fits together. Reviewing code changes becomes difficult. Developers begin to lose their self-confidence and become anxious about making changes to the code. Delivery slows down, and bugs find their way into the system. Time goes on and complexity keeps increasing. At a certain point, it becomes overwhelming. The speed of delivery tapers. Deadlines are missed. Outages happen. If this continues, progress can even grind to a halt. Eventually, someone brings up the idea of rewriting the app. The codebase resembles a Jenga tower on the verge of collapse. Unfortunately, this cautionary tale is based on my own real-world experience on a few different teams. Without taking proactive steps to manage the complexity, software projects often follow a trajectory similar to the one in this story. What can be done to prevent this situation for new projects? And how can we recover from this situation in existing projects? On Complexity One important point about complexity is that it can be broken down into two categories: necessary and unnecessary complexity. For any given application, certain complexity is baked in, or necessary . Put another way, this is \"business logic\". For example, an double-entry accounting app must record each entry in two accounts, a social media app must store relationships between users, and a game must keep track of the player's state. Sometimes complexity is unnecessary . For example, a double-entry accounting app uses the term 'entry' in some places but refers to entries as 'transactions' in other places. Unnecessary complexity is a natural side effect of programming. I'd put over-engineered code and duct-tape fixes into this category as well. Here is a conceptual graph showing the typical progression of necessary and unnecessary complexity in a codebase without refactoring: Why Refactor? By distinguishing necessary and unnecessary complexity, it's easy to see that the only way to bring down the total complexity is to tackle unnecessary complexity. The mechanism we use to do this is refactoring, meaning, that we update the code to simplify it without changing the underlying behavior of the app. If we want to deliver with high speed and confidence over a long time period, we must refactor. When refactoring becomes a regular part of development, it can make a significant impact on the overall complexity: Refactoring Confidently Although the problem and solution are easily stated, the work of refactoring can be extremely challenging! And it's challenging for the same reason that all code changes are challenging: developers become overwhelmed by complexity, and lose confidence that they can change things without breaking them (remember from the definition of 'refactoring' that the behavior of the application cannot change). To refactor successfully, we need to avoid becoming overwhelmed, and this is mainly a preventative effort. Refactoring should begin early on in the project, and be a regular part of development. It's routine maintenance. \"A stitch in time saves nine.\" We also need to make sure the developers have confidence that their changes are correct. This is primarily done through automated testing. Test-Driven Development is the best way to achieve good test coverage. Like refactoring, this is most effective when started early and made a regular part of development. When is it Too Late? In an ideal world, all codebases would get the necessary regular maintenance. But in the real world, this doesn't always happen. What can be done about applications that are already facing significant challenges, like the one I described in my cautionary tale? Unfortunately, this is a very challenging situation and teams can spend a lot of resources digging themselves out of this hole! The hole may be deep, but the basic approach is the same. Validating the expected app behavior with automated tests is paramount, as this creates the confidence needed for major code changes. More often than not, collaboration with users & business stakeholders will be necessay to even define the expected program behavior. Next, refactoring tasks should be identified and the team should consider the cost/benefit of each. A 2x2 prioritization exercise can be useful to identify the highest priority changes. In extreme cases, a rewrite may be the best option. However, this carries major costs and should be considered only as a last resort (in my opinion). A lite variant of this would be a targeted rewrite of certain components, which can provide some benefit without the effort of recreating the entire application from scratch. Learn More About Refactoring Would you like to learn more about how regular refactoring can improve your team's software delivery? Are you struggling with slow progress and buggy software updates? Let's chat !","title":"Refactoring"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#refactoring","text":"Wikipedia defines refactoring as \"restructuring existing source code\u2014changing the factoring\u2014without changing its external behavior.\" I like this definition, but it is a bit technical. A simple way to think of refactoring is cleaning or re-organizing code. To explain why regular refactoring is important, consider this example drawn from personal experience...","title":"Refactoring"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#a-cautionary-tale","text":"A new project begins with a clean slate and developers start hammering away on new features. The codebase is small, so it is easy to see the various pieces and how they fit together. Updating the code is a breeze because there isn't much that can go wrong, and if something breaks it will be easy to notice. Stakeholders are happy with the team's velocity. The team is generally small at this stage and everyone has an intuitive sense of what's going on. Time goes by, and the complexity gradually and steadily increases. After a while, there are dozens of components interacting with each other, and hundreds of individual features supporting several critical user workflows. Each individual contributor only has a partial understanding of the whole system. At this point, the stakeholders are still expecting fast delivery of features. The delivery pressure means things are shipped as soon as they work. Components are added haphazardly without taking time to consider the design of the whole system, code snippets are copy/pasted, and features are shipped without tests. At this point in development, the cost of breaking things is much higher because real users may experience outages. At the same time, it's harder for any single person to grasp how everything fits together. Reviewing code changes becomes difficult. Developers begin to lose their self-confidence and become anxious about making changes to the code. Delivery slows down, and bugs find their way into the system. Time goes on and complexity keeps increasing. At a certain point, it becomes overwhelming. The speed of delivery tapers. Deadlines are missed. Outages happen. If this continues, progress can even grind to a halt. Eventually, someone brings up the idea of rewriting the app. The codebase resembles a Jenga tower on the verge of collapse. Unfortunately, this cautionary tale is based on my own real-world experience on a few different teams. Without taking proactive steps to manage the complexity, software projects often follow a trajectory similar to the one in this story. What can be done to prevent this situation for new projects? And how can we recover from this situation in existing projects?","title":"A Cautionary Tale"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#on-complexity","text":"One important point about complexity is that it can be broken down into two categories: necessary and unnecessary complexity. For any given application, certain complexity is baked in, or necessary . Put another way, this is \"business logic\". For example, an double-entry accounting app must record each entry in two accounts, a social media app must store relationships between users, and a game must keep track of the player's state. Sometimes complexity is unnecessary . For example, a double-entry accounting app uses the term 'entry' in some places but refers to entries as 'transactions' in other places. Unnecessary complexity is a natural side effect of programming. I'd put over-engineered code and duct-tape fixes into this category as well. Here is a conceptual graph showing the typical progression of necessary and unnecessary complexity in a codebase without refactoring:","title":"On Complexity"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#why-refactor","text":"By distinguishing necessary and unnecessary complexity, it's easy to see that the only way to bring down the total complexity is to tackle unnecessary complexity. The mechanism we use to do this is refactoring, meaning, that we update the code to simplify it without changing the underlying behavior of the app. If we want to deliver with high speed and confidence over a long time period, we must refactor. When refactoring becomes a regular part of development, it can make a significant impact on the overall complexity:","title":"Why Refactor?"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#refactoring-confidently","text":"Although the problem and solution are easily stated, the work of refactoring can be extremely challenging! And it's challenging for the same reason that all code changes are challenging: developers become overwhelmed by complexity, and lose confidence that they can change things without breaking them (remember from the definition of 'refactoring' that the behavior of the application cannot change). To refactor successfully, we need to avoid becoming overwhelmed, and this is mainly a preventative effort. Refactoring should begin early on in the project, and be a regular part of development. It's routine maintenance. \"A stitch in time saves nine.\" We also need to make sure the developers have confidence that their changes are correct. This is primarily done through automated testing. Test-Driven Development is the best way to achieve good test coverage. Like refactoring, this is most effective when started early and made a regular part of development.","title":"Refactoring Confidently"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#when-is-it-too-late","text":"In an ideal world, all codebases would get the necessary regular maintenance. But in the real world, this doesn't always happen. What can be done about applications that are already facing significant challenges, like the one I described in my cautionary tale? Unfortunately, this is a very challenging situation and teams can spend a lot of resources digging themselves out of this hole! The hole may be deep, but the basic approach is the same. Validating the expected app behavior with automated tests is paramount, as this creates the confidence needed for major code changes. More often than not, collaboration with users & business stakeholders will be necessay to even define the expected program behavior. Next, refactoring tasks should be identified and the team should consider the cost/benefit of each. A 2x2 prioritization exercise can be useful to identify the highest priority changes. In extreme cases, a rewrite may be the best option. However, this carries major costs and should be considered only as a last resort (in my opinion). A lite variant of this would be a targeted rewrite of certain components, which can provide some benefit without the effort of recreating the entire application from scratch.","title":"When is it Too Late?"},{"location":"2.%20Software%20Engineering%20Practices/02-%20refactoring/#learn-more-about-refactoring","text":"Would you like to learn more about how regular refactoring can improve your team's software delivery? Are you struggling with slow progress and buggy software updates? Let's chat !","title":"Learn More About Refactoring"},{"location":"3.%20AI%20Resources/01%20-%20journal/","text":"","title":"01   journal"},{"location":"3.%20AI%20Resources/02%20-%20generativeAIArtifacts/","text":"Generative AI Artifacts Websites ai-geocities.html headings.html neon-cosmos.html qwen3fanclub.html trees.html bounce.html bounce2.html terminal.html w98form.html","title":"Generative AI Artifacts"},{"location":"3.%20AI%20Resources/02%20-%20generativeAIArtifacts/#generative-ai-artifacts","text":"","title":"Generative AI Artifacts"},{"location":"3.%20AI%20Resources/02%20-%20generativeAIArtifacts/#websites","text":"ai-geocities.html headings.html neon-cosmos.html qwen3fanclub.html trees.html bounce.html bounce2.html terminal.html w98form.html","title":"Websites"},{"location":"4.%20Miscellaneous/01%20-%20goodStuff/","text":"Good Stuff / External Resources Consulting resources Labs Practices Go Fast Forever Learning resources Flexbox Froggy Fun Internet Checkpoint Universal Paperclips","title":"Good Stuff / External Resources"},{"location":"4.%20Miscellaneous/01%20-%20goodStuff/#good-stuff-external-resources","text":"","title":"Good Stuff / External Resources"},{"location":"4.%20Miscellaneous/01%20-%20goodStuff/#consulting-resources","text":"Labs Practices Go Fast Forever","title":"Consulting resources"},{"location":"4.%20Miscellaneous/01%20-%20goodStuff/#learning-resources","text":"Flexbox Froggy","title":"Learning resources"},{"location":"4.%20Miscellaneous/01%20-%20goodStuff/#fun","text":"Internet Checkpoint Universal Paperclips","title":"Fun"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/","text":"Developer Experience Tips Helpful key shortcuts for MacOS Cmd + Shift + 4 = take screenshot to Desktop Cmd + Shift + Ctrl + 4 = take screenshot to Clipboard Cmd + Shift + 5 = take screenshot/recording or update screenshot defaults Helpful apps homebrew to manage app installation from cli see https://brew.sh/ flycut A nice paste buffer. Helpful key shortcuts - Cmd + Shift + v = open paste buffer menu tldr tldr gives you nice digestible examples for cli programs: #> tldr sed sed Edit text in a scriptable manner. See also: `awk`, `ed`. More information: <https://keith.github.io/xcode-man-pages/sed.1.html>. - Replace all `apple` (basic regex) occurrences with `mango` (basic regex) in all input lines and print the result to `stdout`: command | sed 's/apple/mango/g' - Execute a specific script [f]ile and print the result to `stdout`: command | sed -f path/to/script_file.sed - Replace all `apple` (extended regex) occurrences with `APPLE` (extended regex) in all input lines and print the result to `stdout`: command | sed -E 's/(apple)/\\U\\1/g' - Print just a first line to `stdout`: command | sed -n '1p' - Replace all `apple` (basic regex) occurrences with `mango` (basic regex) in a `file` and save a backup of the original to `file.bak`: sed -i bak 's/apple/mango/g' path/to/file ohmyzsh My preferred way to work in the terminal. see https://ohmyz.sh/ https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/dotenv","title":"Developer Experience Tips"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#developer-experience-tips","text":"","title":"Developer Experience Tips"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#helpful-key-shortcuts-for-macos","text":"Cmd + Shift + 4 = take screenshot to Desktop Cmd + Shift + Ctrl + 4 = take screenshot to Clipboard Cmd + Shift + 5 = take screenshot/recording or update screenshot defaults","title":"Helpful key shortcuts for MacOS"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#helpful-apps","text":"","title":"Helpful apps"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#homebrew","text":"to manage app installation from cli see https://brew.sh/","title":"homebrew"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#flycut","text":"A nice paste buffer. Helpful key shortcuts - Cmd + Shift + v = open paste buffer menu","title":"flycut"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#tldr","text":"tldr gives you nice digestible examples for cli programs: #> tldr sed sed Edit text in a scriptable manner. See also: `awk`, `ed`. More information: <https://keith.github.io/xcode-man-pages/sed.1.html>. - Replace all `apple` (basic regex) occurrences with `mango` (basic regex) in all input lines and print the result to `stdout`: command | sed 's/apple/mango/g' - Execute a specific script [f]ile and print the result to `stdout`: command | sed -f path/to/script_file.sed - Replace all `apple` (extended regex) occurrences with `APPLE` (extended regex) in all input lines and print the result to `stdout`: command | sed -E 's/(apple)/\\U\\1/g' - Print just a first line to `stdout`: command | sed -n '1p' - Replace all `apple` (basic regex) occurrences with `mango` (basic regex) in a `file` and save a backup of the original to `file.bak`: sed -i bak 's/apple/mango/g' path/to/file","title":"tldr"},{"location":"4.%20Miscellaneous/02%20-%20devExperience/#ohmyzsh","text":"My preferred way to work in the terminal. see https://ohmyz.sh/ https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/dotenv","title":"ohmyzsh"},{"location":"4.%20Miscellaneous/03%20-%20docker/","text":"Docker Internal DNS Connecting from one docker container to another using 'localhost' doesn't work. Instead, use the docker internal dns address: EXTERNAL_URL=http://host.docker.internal:5001 Github Container Registry Authenticate with GHCR Go to https://github.com/settings/tokens and create a \"classic token\". Include write:packages and read:packages permissions Use a descriptive name , like 'Home PC (Docker)'. You will likely have many tokens in use in different places. Having a descriptive name will be useful when a token expires. Copy the generated token and run this command: \u279c ~ export CR_PAT=YOUR_TOKEN_HERE \u279c ~ echo $CR_PAT | docker login ghcr.io -u tdurtschi --password-stdin For more info, check out Working with the container registry (Github) MySQL Quickstart with docker-compose This example initializes a MariaDB container and a user with specified password. To get started, save the following file in your current directory as docker-compose.yml . The docker image will be downloaded (this may take a few minutes) and then the container will run locally. # This file contains the configuration needed to run a local MariaDB # (MySQL compatible) server for development purposes. # # To start the MariaDB server, run: # > docker-compose up # # If you need to re-initialize the database (for example, when schema updates # are available), you must first destroy the container: # > docker-compose down # # Connect to this server using the connection string: # 'server=localhost;port=3306;database=local_db;uid=local_user;password=password;' version: \"3.9\" services: mysql: image: mariadb:10.7 ports: - 3306:3306 volumes: - ./MySQL/init:/docker-entrypoint-initdb.d:ro environment: - MYSQL_ROOT_PASSWORD=p4ssw0rd - MYSQL_DATABASE=local_db - MYSQL_USER=local_user - MYSQL_PASSWORD=password Note: The first time the container runs, it will also run any .sql files in the ./MySQL/init directory. This can be used to creat an initial schema, add test data, etc. I recommend adding numerical prefixes and descriptions for easier readability, i.e. 01_create_table.sql , 02_add_some_data.sql . Initialization scripts are run in alphabetical order, so this will allow you to partition the schema into multiple files, or create forward migrations. Learn more about Docker Compose . Learn more about the docker-compose.yml file.","title":"Docker"},{"location":"4.%20Miscellaneous/03%20-%20docker/#docker","text":"","title":"Docker"},{"location":"4.%20Miscellaneous/03%20-%20docker/#internal-dns","text":"Connecting from one docker container to another using 'localhost' doesn't work. Instead, use the docker internal dns address: EXTERNAL_URL=http://host.docker.internal:5001","title":"Internal DNS"},{"location":"4.%20Miscellaneous/03%20-%20docker/#github-container-registry","text":"Authenticate with GHCR Go to https://github.com/settings/tokens and create a \"classic token\". Include write:packages and read:packages permissions Use a descriptive name , like 'Home PC (Docker)'. You will likely have many tokens in use in different places. Having a descriptive name will be useful when a token expires. Copy the generated token and run this command: \u279c ~ export CR_PAT=YOUR_TOKEN_HERE \u279c ~ echo $CR_PAT | docker login ghcr.io -u tdurtschi --password-stdin For more info, check out Working with the container registry (Github)","title":"Github Container Registry"},{"location":"4.%20Miscellaneous/03%20-%20docker/#mysql-quickstart-with-docker-compose","text":"This example initializes a MariaDB container and a user with specified password. To get started, save the following file in your current directory as docker-compose.yml . The docker image will be downloaded (this may take a few minutes) and then the container will run locally. # This file contains the configuration needed to run a local MariaDB # (MySQL compatible) server for development purposes. # # To start the MariaDB server, run: # > docker-compose up # # If you need to re-initialize the database (for example, when schema updates # are available), you must first destroy the container: # > docker-compose down # # Connect to this server using the connection string: # 'server=localhost;port=3306;database=local_db;uid=local_user;password=password;' version: \"3.9\" services: mysql: image: mariadb:10.7 ports: - 3306:3306 volumes: - ./MySQL/init:/docker-entrypoint-initdb.d:ro environment: - MYSQL_ROOT_PASSWORD=p4ssw0rd - MYSQL_DATABASE=local_db - MYSQL_USER=local_user - MYSQL_PASSWORD=password Note: The first time the container runs, it will also run any .sql files in the ./MySQL/init directory. This can be used to creat an initial schema, add test data, etc. I recommend adding numerical prefixes and descriptions for easier readability, i.e. 01_create_table.sql , 02_add_some_data.sql . Initialization scripts are run in alphabetical order, so this will allow you to partition the schema into multiple files, or create forward migrations. Learn more about Docker Compose . Learn more about the docker-compose.yml file.","title":"MySQL Quickstart with docker-compose"},{"location":"4.%20Miscellaneous/04%20-%20dotnet/","text":"Dotnet Override a value in appsettings.json with environment variable To override application config using environment variables, use the following naming convention: # For this appsettings.json file: {\"MyService\": {\"Enabled\": \"false\"}} # Use an override for MyService.Enabled: # (Note the double underscore used instead of colon in env variable name) MyService__Enabled=\"true\" dotnet run --project MyProject # Use defaults from appsettings.json: dotnet run --project MyProject","title":"Dotnet"},{"location":"4.%20Miscellaneous/04%20-%20dotnet/#dotnet","text":"","title":"Dotnet"},{"location":"4.%20Miscellaneous/04%20-%20dotnet/#override-a-value-in-appsettingsjson-with-environment-variable","text":"To override application config using environment variables, use the following naming convention: # For this appsettings.json file: {\"MyService\": {\"Enabled\": \"false\"}} # Use an override for MyService.Enabled: # (Note the double underscore used instead of colon in env variable name) MyService__Enabled=\"true\" dotnet run --project MyProject # Use defaults from appsettings.json: dotnet run --project MyProject","title":"Override a value in appsettings.json with environment variable"},{"location":"4.%20Miscellaneous/05%20-%20git/","text":"Git My aliases I find these git aliases useful to reduce typing. In particular, I use git lol and git lola daily, since they are very helpful commands and who can remember all those flags? To use a git alias, just substitute the command with the alias. E.g. git st instead of git status . To use, amend your ~/.gitconfig file with the aliases you want to include: # This is Git's per-user configuration file. [user] # ... [alias] st = status ci = commit br = branch co = checkout ds = diff --staged lg = log -p lol = log --graph --decorate --pretty=oneline --abbrev-commit lola = log --graph --decorate --pretty=oneline --abbrev-commit --all","title":"Git"},{"location":"4.%20Miscellaneous/05%20-%20git/#git","text":"","title":"Git"},{"location":"4.%20Miscellaneous/05%20-%20git/#my-aliases","text":"I find these git aliases useful to reduce typing. In particular, I use git lol and git lola daily, since they are very helpful commands and who can remember all those flags? To use a git alias, just substitute the command with the alias. E.g. git st instead of git status . To use, amend your ~/.gitconfig file with the aliases you want to include: # This is Git's per-user configuration file. [user] # ... [alias] st = status ci = commit br = branch co = checkout ds = diff --staged lg = log -p lol = log --graph --decorate --pretty=oneline --abbrev-commit lola = log --graph --decorate --pretty=oneline --abbrev-commit --all","title":"My aliases"},{"location":"4.%20Miscellaneous/06%20-%20kuberenetes/","text":"Kubernetes Custom kubectl shortcuts These examples use zsh, but could be easily adapted to bash. To edit the zsh config file: vim ~/.zshrc Note: make sure you restart the terminal after making these updates, or run zsh to create a new session. Here are the aliases I use today: alias k=kubectl alias kdev=\"kubectl config set-context --current --namespace=dev\" alias kqa=\"kubectl config set-context --current --namespace=qa\" alias kuat=\"kubectl config set-context --current --namespace=uat\" alias kgp=\"kubectl get pods\" kenv() { kubectl config set-context --current --namespace=$1; } kbash() { kubectl exec --stdin --tty $1 -- /bin/bash; } As you can see, I use alias to create shortcuts for very common commands. If a shortcut requires an argument, you can create a function. Example usage: > kqa Context \"k8s-context\" modified. > kgp NAME READY STATUS RESTARTS AGE my-service-99bcfcdf5-9vvkl 1/1 Running 0 25d > kbash my-service-99bcfcdf5-9vvkl root@my-service-99bcfcdf5-9vvkl:/> k9s Consider k9s to simplify kubernetes management tasks including: Describing pods Executing shell on a pod Port forwarding Vewing Logs","title":"Kubernetes"},{"location":"4.%20Miscellaneous/06%20-%20kuberenetes/#kubernetes","text":"","title":"Kubernetes"},{"location":"4.%20Miscellaneous/06%20-%20kuberenetes/#custom-kubectl-shortcuts","text":"These examples use zsh, but could be easily adapted to bash. To edit the zsh config file: vim ~/.zshrc Note: make sure you restart the terminal after making these updates, or run zsh to create a new session. Here are the aliases I use today: alias k=kubectl alias kdev=\"kubectl config set-context --current --namespace=dev\" alias kqa=\"kubectl config set-context --current --namespace=qa\" alias kuat=\"kubectl config set-context --current --namespace=uat\" alias kgp=\"kubectl get pods\" kenv() { kubectl config set-context --current --namespace=$1; } kbash() { kubectl exec --stdin --tty $1 -- /bin/bash; } As you can see, I use alias to create shortcuts for very common commands. If a shortcut requires an argument, you can create a function. Example usage: > kqa Context \"k8s-context\" modified. > kgp NAME READY STATUS RESTARTS AGE my-service-99bcfcdf5-9vvkl 1/1 Running 0 25d > kbash my-service-99bcfcdf5-9vvkl root@my-service-99bcfcdf5-9vvkl:/>","title":"Custom kubectl shortcuts"},{"location":"4.%20Miscellaneous/06%20-%20kuberenetes/#k9s","text":"Consider k9s to simplify kubernetes management tasks including: Describing pods Executing shell on a pod Port forwarding Vewing Logs","title":"k9s"}]}